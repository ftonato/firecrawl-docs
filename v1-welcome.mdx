---
title: Welcome to V1
description: "Firecrawl allows you to turn entire websites into LLM-ready markdown"
og:title: "Welcome to V1 | Firecrawl"
og:description: "Firecrawl allows you to turn entire websites into LLM-ready markdown"
---

import InstallationPython from "/snippets/v1/installation/python.mdx";
import InstallationNode from "/snippets/v1/installation/js.mdx";
import InstallationGo from "/snippets/v1/installation/go.mdx";
import InstallationRust from "/snippets/v1/installation/rust.mdx";
import ScrapePython from "/snippets/v1/scrape/base/python.mdx";
import ScrapeNode from "/snippets/v1/scrape/base/js.mdx";
import ScrapeGo from "/snippets/v1/scrape/base/go.mdx";
import ScrapeRust from "/snippets/v1/scrape/base/rust.mdx";
import ScrapeCURL from "/snippets/v1/scrape/base/curl.mdx";
import ScrapeResponse from "/snippets/v1/scrape/base/output.mdx";
import MapPython from "/snippets/v1/map/base/python.mdx";
import MapJavaScript from "/snippets/v1/map/base/js.mdx";
import MapGo from "/snippets/v1/map/base/go.mdx";
import MapRust from "/snippets/v1/map/base/rust.mdx";
import MapCURL from "/snippets/v1/map/base/curl.mdx";
import MapResponse from "/snippets/v1/map/base/output.mdx";
import CrawlWebSocketPythonBase from "/snippets/v1/crawl-websocket/base/python.mdx";
import CrawlWebSocketNodeBase from "/snippets/v1/crawl-websocket/base/js.mdx";
import ExtractCURL from "/snippets/v1/llm-extract/base/curl.mdx";
import ExtractPython from "/snippets/v1/llm-extract/base/python.mdx";
import ExtractNode from "/snippets/v1/llm-extract/base/js.mdx";
import ExtractOutput from "/snippets/v1/llm-extract/base/output.mdx";
import ExtractNoSchemaCURL from "/snippets/v1/llm-extract/no-schema/curl.mdx";
import ExtractNoSchemaOutput from "/snippets/v1/llm-extract/no-schema/output.mdx";


Firecrawl V1 is here! With that we introduce a more reliable and developer friendly API.

Here is what's new:

- Output Formats for `/scrape`. Choose what formats you want your output in.
- New [`/map` endpoint](/features/map) for getting most of the URLs of a webpage.
- Developer friendly API for `/crawl/{id}` status.
- 2x Rate Limits for all plans.
- [Go SDK](/sdks/go) and [Rust SDK](/sdks/rust)
- Teams support
- API Key Management in the dashboard.
- `onlyMainContent` is now default to `true`.
- `/crawl` webhooks and websocket support.


## Scrape Formats

You can now choose what formats you want your output in. You can specify multiple output formats. Supported formats are:

- Markdown (markdown)
- HTML (html)
- Raw HTML (rawHtml) (with no modifications)
- Screenshot (screenshot or screenshot@fullPage)
- Links (links)

Output keys will match the format you choose.

<CodeGroup>

  <ScrapePython />

  <ScrapeNode />

  <ScrapeGo />

  <ScrapeRust />

  <ScrapeCURL />

</CodeGroup>

### Response

SDKs will return the data object directly. cURL will return the payload exactly as shown below.

<ScrapeResponse />

## Introducing /map (Alpha)

The easiest way to go from a single url to a map of the entire website.

### Usage

<CodeGroup>

<MapPython />
<MapJavaScript />
<MapGo />
<MapRust />
<MapCURL />

</CodeGroup>

### Response

SDKs will return the data object directly. cURL will return the payload exactly as shown below.

<MapResponse />

## WebSockets

To crawl a website with WebSockets, use the `Crawl URL and Watch` method.

<CodeGroup>

<CrawlWebSocketPythonBase />
<CrawlWebSocketNodeBase />

</CodeGroup>

## Extract format

LLM extraction is now available in v1 under the `extract` format. To extract structured from a page, you can pass a schema to the endpoint or just provide a prompt.

<CodeGroup>

<ExtractPython />
<ExtractNode />
<ExtractCURL />

</CodeGroup>

Output:

<ExtractOutput />

### Extracting without schema (New)

You can now extract without a schema by just passing a `prompt` to the endpoint. The llm chooses the structure of the data.

<CodeGroup>

<ExtractNoSchemaCURL />

</CodeGroup>

Output:

<ExtractNoSchemaOutput />

## Crawl Webhook (Coming soon)