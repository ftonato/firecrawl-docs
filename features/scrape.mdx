---
title: "Scrape"
description: "Turn any url into clean data"
icon: "markdown"
og:title: "Scrape | Firecrawl"
og:description: "Turn any url into clean data"
---

import InstallationPython from "/snippets/v1/installation/base/python.mdx";
import InstallationNode from "/snippets/v1/installation/base/js.mdx";
import InstallationGo from "/snippets/v1/installation/base/go.mdx";
import InstallationRust from "/snippets/v1/installation/base/rust.mdx";
import InstallationCURL from "/snippets/v1/installation/base/curl.mdx";
import ScrapePython from "/snippets/v1/scrape/base/python.mdx";
import ScrapeNode from "/snippets/v1/scrape/base/js.mdx";
import ScrapeGo from "/snippets/v1/scrape/base/go.mdx";
import ScrapeRust from "/snippets/v1/scrape/base/rust.mdx";
import ScrapeCURL from "/snippets/v1/scrape/base/curl.mdx";
import ScrapeResponse from "/snippets/v1/scrape/base/output.mdx";

## Scraping with Firecrawl

Firecrawl converts web pages into markdown, ideal for LLM applications. Here's why:

1. **Complexities Managed:**
   Handles proxies, caching, rate limits, and JavaScript-blocked content for smooth scraping.

2. **Dynamic Content:**
   Gathers data from JavaScript-rendered websites, pdfs, images etc.

3. **Markdown or Structured data conversion:**
   Converts collected data into clean markdown or structured output, perfect for LLM processing or any other task.

For more details, refer to the [Scrape Endpoint API Reference](https://docs.firecrawl.dev/api-reference/endpoint/scrape).


## Scrape a URL

### /scrape endpoint

Used to scrape a URL and get its content.

### Installation 

<CodeGroup>

  <InstallationPython />

  <InstallationNode />

  <InstallationGo />
  
  <InstallationRust />

</CodeGroup>

### Usage

<CodeGroup>

  <ScrapePython />

  <ScrapeNode />

  <ScrapeGo />

  <ScrapeRust />

  <ScrapeCURL />

</CodeGroup>

### Response

SDKs will return the data object directly. cURL will return they payload exactly as shown below

<ScrapeResponse />

