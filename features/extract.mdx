---
title: 'Extract'
description: 'Extract structured data from pages using LLMs'
icon: 'wand-magic-sparkles'
og:title: "Extract | Firecrawl"
og:description: "Extract structured data from pages using LLMs"
---

import ExtractCURL from "/snippets/v1/extract/base/curl.mdx";
import ExtractPython from "/snippets/v1/extract/base/python.mdx";
import ExtractNode from "/snippets/v1/extract/base/js.mdx";
import ExtractOutput from "/snippets/v1/extract/base/output.mdx";
import ExtractNoSchemaCURL from "/snippets/v1/extract/no-schema/curl.mdx";
import ExtractNoSchemaOutput from "/snippets/v1/extract/no-schema/output.mdx";

## Introducing /extract

Efficiently extract structured data from a single or multiple URLs using Large Language Models (LLMs). This endpoint is ideal for:
- Automating data extraction from web pages
- Ensuring data consistency with optional schema definitions
- Reducing manual data handling and enhancing processing efficiency

## Considerations

The `/extract` endpoint streamlines data extraction, offering flexible schema definitions. Optimal results may require prompt adjustments. Your feedback is encouraged to enhance this service.

## Extracting Data

### /extract endpoint

Used to extract structured data from multiple URLs.

### Usage
<CodeGroup>

<ExtractPython />
<ExtractNode />
<ExtractCURL />

</CodeGroup>

For more details about the parameters, refer to the [API Reference](https://docs.firecrawl.dev/api-reference/endpoint/extract).

### Response

Receive the scraped data in the structured format defined by your schema. You can then use this data as needed in your application or for further processing.

<ExtractOutput />

### Extracting without schema

You can now extract without a schema by just passing a `prompt` to the endpoint. The LLM chooses the structure of the data.

<CodeGroup>

<ExtractNoSchemaCURL />

</CodeGroup>

### Response

<ExtractNoSchemaOutput />