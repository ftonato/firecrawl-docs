---
title: 'Python'
description: 'Firecrawl Python SDK is a wrapper around the Firecrawl API to help you easily turn websites into markdown.'
icon: 'python'
og:title: "Python SDK | Firecrawl"
og:description: "Firecrawl Python SDK is a wrapper around the Firecrawl API to help you easily turn websites into markdown."
---

import InstallationPython from '/snippets/v1/installation/python.mdx'
import ScrapePythonShort from '/snippets/v1/scrape/short/python.mdx'
import CrawlPythonShort from '/snippets/v1/crawl/short/python.mdx'
import CheckCrawlStatusPythonShort from '/snippets/v1/crawl-status/short/python.mdx'
import MapPythonShort from '/snippets/v1/map/short/python.mdx'
import ScrapeAndCrawlExamplePython from '/snippets/v1/scrape-and-crawl/python.mdx'

## Installation

To install the Firecrawl Python SDK, you can use pip:

<InstallationPython />

## Usage

1. Get an API key from [firecrawl.dev](https://firecrawl.dev)
2. Set the API key as an environment variable named `FIRECRAWL_API_KEY` or pass it as a parameter to the `FirecrawlApp` class.


Here's an example of how to use the SDK:

<ScrapeAndCrawlExamplePython />

### Scraping a URL

To scrape a single URL, use the `scrape_url` method. It takes the URL as a parameter and returns the scraped data as a dictionary.

<ScrapePythonShort />

### Crawling a Website

To crawl a website, use the `crawl_url` method. It takes the starting URL and optional parameters as arguments. The `params` argument allows you to specify additional options for the crawl job, such as the maximum number of pages to crawl, allowed domains, and the output format.

The `wait_until_done` parameter determines whether the method should wait for the crawl job to complete before returning the result. If set to `True`, the method will periodically check the status of the crawl job until it is completed or the specified `timeout` (in seconds) is reached. If set to `False`, the method will return immediately with the job ID, and you can manually check the status of the crawl job using the `check_crawl_status` method.

<CrawlPythonShort />

If `wait_until_done` is set to `True`, the `crawl_url` method will return the crawl result once the job is completed. If the job fails or is stopped, an exception will be raised.

### Checking Crawl Status

To check the status of a crawl job, use the `check_crawl_status` method. It takes the job ID as a parameter and returns the current status of the crawl job.

<CheckCrawlStatusPythonShort />

### Map a Website

Use `map_url` to generate a list of URLs from a website. The `params` argument let you customize the mapping process, including options to exclude subdomains or to utilize the sitemap.

<MapPythonShort />

## Error Handling

The SDK handles errors returned by the Firecrawl API and raises appropriate exceptions. If an error occurs during a request, an exception will be raised with a descriptive error message.